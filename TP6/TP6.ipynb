{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33e8ffeb",
   "metadata": {},
   "source": [
    "## TP6\n",
    "\n",
    "Una empresa de transporte quiere monitorear la actividad de sus conductores durante el manejo Para ello se propone implementar\n",
    "un detector de somnolencia en tiempo real tomando como datos de entrada frames provenientes de una cámara que apunta al rosto\n",
    "del conductor\n",
    "\n",
    "1. Implementar un detector Haar de caras (vista frontal)\n",
    "\n",
    "2. En esa ROI detectar los ojos (Se puede usar otro detector Haar\n",
    "\n",
    "3. Mediante alguna de las técnicas vistas en clase detectar si ambos ojos están abiertos o cerrados y mostrar el estado de la detección sobre el frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1b3db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Si queremos que las imágenes sean mostradas en una ventana emergente quitar el inline\n",
    "# %matplotlib inline\n",
    "%matplotlib\n",
    "\n",
    "# Importamos las librerías necesarias\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1699b3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "eye_cascade = cv.CascadeClassifier('haarcascade_eye_tree_eyeglasses.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd90282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_compare(img_last, img_current):\n",
    "\n",
    "    bins_last = cv.calcHist([img_last],[0],None,[256],[0,256])\n",
    "    bins_current = cv.calcHist([img_current],[0],None,[256],[0,256])\n",
    "    \n",
    "    return cv.compareHist(bins_last, bins_current, cv.HISTCMP_CORREL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc9a896f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posicion relativa de los ojos/cara: [[72, 94, 60, 60], [193, 94, 65, 65]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cap = cv.VideoCapture(1)\n",
    "selected_roi = False\n",
    "show_track = True\n",
    "\n",
    "fourcc = cv.VideoWriter_fourcc(*'MP4V')\n",
    "out = cv.VideoWriter('output.mp4', fourcc, 5, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "\n",
    "first_detection_eyes = False\n",
    "start_detection = False\n",
    "relative_eyes = []\n",
    "\n",
    "ojo1_last = 0\n",
    "ojo2_last = 0\n",
    "\n",
    "\n",
    "while(1):\n",
    "\n",
    "    # 480 x 640\n",
    "    ret ,frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "          \n",
    "        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        if start_detection:\n",
    "            # Detect faces in the image\n",
    "            faces = face_cascade.detectMultiScale(gray, 1.1, minNeighbors=5)#, minSize= (100,130),maxSize=(200,400))\n",
    "\n",
    "            if len(faces) > 0:\n",
    "                for (x,y,w,h) in faces:\n",
    "                    # Le dibujamos un rectángulo amarillo\n",
    "                    cv.rectangle(frame,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "                    # Definimos las ROIs en la imagen gris y color\n",
    "                    roi_gray = gray[y:y+h, x:x+w] \n",
    "                    roi_color = frame[y:y+h, x:x+w] \n",
    "\n",
    "                    if first_detection_eyes == False:\n",
    "                        # Para cada rostro hallado le buscamos los ojos\n",
    "                        eyes = eye_cascade.detectMultiScale(roi_gray, 1.2, 8)\n",
    "                        # En los ojos hallados les dibujamos rectángulos\n",
    "                        if len(eyes) == 2:\n",
    "\n",
    "                            first_detection_eyes = True\n",
    "\n",
    "                            for (ex,ey,ew,eh) in eyes:\n",
    "                                cv.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "                                relative_eyes.append([ex, ey, ew, eh])\n",
    "                            \n",
    "                            eye1= relative_eyes[0]\n",
    "                            eye2= relative_eyes[1]\n",
    "                \n",
    "                            ojo1_last = roi_gray[eye1[1]:eye1[1]+eye1[3], eye1[0]:eye1[0]+eye1[2]]\n",
    "                            ojo2_last = roi_gray[eye2[1]:eye2[1]+eye2[3], eye2[0]:eye2[0]+eye2[2]]\n",
    "\n",
    "                            print(f\"Posicion relativa de los ojos/cara: {relative_eyes}\")\n",
    "\n",
    "                    else:\n",
    "                        for eye in relative_eyes:\n",
    "                            cv.rectangle(roi_color,(eye[0],eye[1]),(eye[0]+eye[2],eye[1]+eye[3]),(0,255,0),2)\n",
    "                        \n",
    "                        eye1= relative_eyes[0]\n",
    "                        eye2= relative_eyes[1]\n",
    "                        ojo1 = roi_gray[eye1[1]:eye1[1]+eye1[3], eye1[0]:eye1[0]+eye1[2]]\n",
    "                        ojo2 = roi_gray[eye2[1]:eye2[1]+eye2[3], eye2[0]:eye2[0]+eye2[2]]\n",
    "                        \n",
    "                        ojo1_corr = hist_compare(ojo1_last, ojo1)\n",
    "                        ojo2_corr = hist_compare(ojo2_last, ojo2)\n",
    "                    \n",
    "                        correlation = (ojo1_corr + ojo2_corr)/2\n",
    "                        \n",
    "                        cv.putText(frame, f'corr_hist = {correlation}', (20, 450), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255 ), 2, cv.LINE_AA)\n",
    "\n",
    "                        if correlation <= 0.9:\n",
    "                            cv.putText(frame, 'Deteccion ojos cerrados', (20, 100), cv.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv.LINE_AA)\n",
    "\n",
    "                    \n",
    "        if first_detection_eyes:  \n",
    "            cv.putText(frame, f'Ojos Detectados', (20, 30), cv.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv.LINE_AA)\n",
    "            \n",
    "        \n",
    "        cv.imshow('Face Recognition', frame)\n",
    "        out.write(frame)\n",
    "        \n",
    "        key = cv.waitKey(10) & 0xFF\n",
    "            \n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "        elif key==ord('s') and ~start_detection:\n",
    "            start_detection = True\n",
    "            \n",
    "    else:\n",
    "        break\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "out.release()\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
